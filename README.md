# Japanese Search Engine

A Flask-based search engine designed specifically for Japanese text processing using Janome tokenization and TF-IDF scoring.

## Project Overview

This search engine provides full-text search capabilities for Japanese documents with a clean web interface and REST API. It uses Janome for Japanese tokenization and implements TF-IDF scoring for relevance ranking.

## Project Structure

```
search_engine/
â”œâ”€â”€ app/                          # Flask application package
â”‚   â”œâ”€â”€ __init__.py              # App factory with blueprint registration
â”‚   â”œâ”€â”€ routes/                  # URL routes and endpoints
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py             # Web interface routes (/, /search)
â”‚   â”‚   â””â”€â”€ api.py              # REST API routes (/api/*)
â”‚   â”œâ”€â”€ services/               # Core search logic
â”‚   â”‚   â”œâ”€â”€ simple_search.py    # Custom Japanese search with TF-IDF
â”‚   â”‚   â”œâ”€â”€ whoosh_simple.py    # Whoosh-based search implementation
â”‚   â”‚   â”œâ”€â”€ query_processor.py  # Query parsing and processing
â”‚   â”‚   â”œâ”€â”€ search_service.py   # Main search service (uses Whoosh)
â”‚   â”‚   â”œâ”€â”€ search_service_whoosh.py # Alternative Whoosh service
â”‚   â”‚   â””â”€â”€ japanese_text_processor.py # Text processing utilities
â”‚   â”œâ”€â”€ models/                 # Data models (empty for now)
â”‚   â””â”€â”€ utils/                  # Utility functions (empty for now)
â”œâ”€â”€ templates/                  # HTML templates
â”‚   â”œâ”€â”€ base.html              # Base template with Bootstrap
â”‚   â”œâ”€â”€ index.html             # Main search page
â”‚   â””â”€â”€ search.html            # Search results page
â”œâ”€â”€ static/                    # Static assets
â”‚   â”œâ”€â”€ css/
â”‚   â”‚   â””â”€â”€ style.css          # Custom styles
â”‚   â””â”€â”€ js/
â”‚       â””â”€â”€ search.js          # Frontend JavaScript
â”œâ”€â”€ data/                      # Data storage
â”‚   â”œâ”€â”€ search_index.json      # JSON-based search index
â”‚   â””â”€â”€ documents/             # Document storage (empty)
â”œâ”€â”€ tests/                     # Test suite
â”‚   â”œâ”€â”€ __init__.py           # Test package
â”‚   â”œâ”€â”€ test_search_engine.py # Main search engine tests
â”‚   â”œâ”€â”€ test_whoosh_simple.py # Whoosh implementation tests
â”‚   â”œâ”€â”€ test_api_routes.py    # API endpoint tests
â”‚   â”œâ”€â”€ test_tokenization_behavior.py # Tokenization tests
â”‚   â””â”€â”€ compare_implementations.py # Engine comparison
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ run.py                     # Application entry point
â””â”€â”€ README.md                  # This documentation
```

## Key Components

### 1. Search Engine Implementations

#### Custom Implementation (`simple_search.py`)
- **Japanese tokenization** using Janome
- **Custom TF-IDF scoring** for relevance ranking  
- **Inverted index** for fast lookups
- **JSON persistence** for data storage
- **Lightweight and educational**

#### Whoosh Implementation (`whoosh_simple.py`)
- **Whoosh-powered indexing** with Japanese preprocessing
- **Industry-standard TF-IDF scoring**
- **Multi-field search** capabilities
- **High-performance binary index**
- **Scalable for large datasets**

### 2. Search Service Layer
- **`search_service.py`** - Custom implementation service
- **`search_service_whoosh.py`** - Whoosh implementation service
- **Query processing** with timing and error handling
- **Unified API** for both implementations

### 3. Flask Web Interface
- **Main page** (`/`) - Clean search interface
- **Results page** (`/search`) - Search results with scores
- **REST API** (`/api/search`, `/api/add_document`)
- **Bootstrap styling** with Japanese UI

### 4. Japanese Text Processing
- **Tokenization**: Extracts åè© (nouns), å‹•è© (verbs), å½¢å®¹è© (adjectives), å‰¯è© (adverbs)
- **Stop word filtering**: Removes common particles
- **Query processing**: Handles phrases, title searches

## Installation

### Option 1: Using uv (Recommended)

1. **Create and activate virtual environment**:
   ```bash
   uv venv
   source .venv/bin/activate  # Linux/Mac
   # or on Windows: .venv\Scripts\activate
   ```

2. **Install dependencies**:
   ```bash
   uv pip install -r requirements.txt
   ```

3. **Run the application**:
   ```bash
   uv run python run.py
   ```

### Option 2: Direct uv execution (No activation needed)

```bash
# Install dependencies and run directly
uv run --with-requirements requirements.txt python run.py

# Or run tests
uv run --with-requirements requirements.txt python test_search_engine.py
```

4. **Access the web interface**:
   Open http://127.0.0.1:5000 in your browser

## Usage

### Web Interface

1. **Main Search Page** (`/`)
   - Enter Japanese search terms
   - Choose search type (all content or title only)
   - Set result limit (10, 20, or 50)

2. **Search Results** (`/search`)
   - View results with relevance scores
   - Click titles to visit original URLs
   - See search statistics and timing

### REST API

All API endpoints are prefixed with `/api/` and return JSON responses.

#### Search Documents
```bash
GET /api/search?q=æ¤œç´¢èª&limit=10&type=auto
```

#### Add Single Document
```bash
POST /api/add_document
Content-Type: application/json

{
    "id": "doc1",
    "title": "æ–‡æ›¸ã®ã‚¿ã‚¤ãƒˆãƒ«",
    "content": "æ–‡æ›¸ã®å†…å®¹...",
    "url": "https://example.com/doc1"
}
```

#### Add Multiple Documents (Batch)
```bash
POST /api/add_documents
Content-Type: application/json

{
    "documents": [
        {
            "id": "doc1",
            "title": "æ–‡æ›¸1ã®ã‚¿ã‚¤ãƒˆãƒ«",
            "content": "æ–‡æ›¸1ã®å†…å®¹...",
            "url": "https://example.com/doc1"
        },
        {
            "id": "doc2", 
            "title": "æ–‡æ›¸2ã®ã‚¿ã‚¤ãƒˆãƒ«",
            "content": "æ–‡æ›¸2ã®å†…å®¹...",
            "url": "https://example.com/doc2"
        }
    ]
}
```

#### Get Statistics
```bash
GET /api/stats
```

#### Clear Search Index
```bash
POST /api/clear_index
```

#### Optimize Search Index
```bash
POST /api/optimize_index
```

## How It Works

### 1. Document Indexing
```python
# Add documents via API or batch
search_service.add_document(id, title, content, url)
```

### 2. Search Process
1. User enters Japanese query
2. Query is tokenized by Janome
3. Tokens are matched against inverted index
4. TF-IDF scores are calculated for relevance
5. Results are sorted and returned with snippets

### 3. Japanese Tokenization
```python
# Example tokenization
text = "æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤"
tokens = ["æ©Ÿæ¢°", "å­¦ç¿’", "åŸºç¤"]  # Extracted nouns
```

## Features

âœ… **Japanese tokenization** with proper part-of-speech filtering  
âœ… **TF-IDF relevance scoring** for quality results  
âœ… **Title-only search** with `title:` prefix  
âœ… **Phrase search** with quotes  
âœ… **Web interface** with clean Japanese UI  
âœ… **REST API** for programmatic access  
âœ… **JSON persistence** for data storage  
âœ… **Search statistics** and timing  

## Search Tips

- **Basic search**: `æ©Ÿæ¢°å­¦ç¿’` - searches all content
- **Title search**: `title:Python` - searches only in titles  
- **Phrase search**: `"ãƒ‡ãƒ¼ã‚¿åˆ†æ"` - exact phrase matching
- **Multiple terms**: `Flask Django` - finds documents with both terms

## Testing

All test files are organized in the `tests/` directory. Run any test script to see example functionality:

```bash
# Main search engine test
uv run python tests/test_search_engine.py

# Test Whoosh implementation  
uv run python tests/test_whoosh_simple.py

# Test API routes
uv run python tests/test_api_routes.py

# Test tokenization behavior
uv run python tests/test_tokenization_behavior.py

# Compare both implementations
uv run python tests/compare_implementations.py
```

This will:
1. Add sample Japanese documents
2. Test various search queries
3. Display results with scores
4. Show search statistics

## Technical Details

### TF-IDF Scoring
- **Term Frequency (TF)**: How often a term appears in a document
- **Inverse Document Frequency (IDF)**: How rare a term is across all documents
- **Score**: TF Ã— IDF for relevance ranking

### Japanese Text Processing
- Uses Janome tokenizer for morphological analysis
- Filters by part-of-speech (åè©, å‹•è©, å½¢å®¹è©, å‰¯è©)
- Removes common stop words and particles
- Handles both hiragana and katakana

### Data Storage
- Documents stored in JSON format
- Inverted index for fast term lookups
- Persistent storage in `data/search_index.json`

## Frontend Development

For frontend developers who want to integrate with this search engine backend:

ğŸ“š **[Frontend API Documentation](./FRONTEND_API_DOCS.md)** - Complete guide covering:
- All backend API endpoints and parameters
- Authentication system integration
- Search functionality with Japanese text processing
- Prefecture filtering and metadata handling
- Form structures and client-side validation
- Performance considerations and best practices

The documentation provides everything needed to build a custom frontend or integrate the search engine into existing applications.

## Dependencies

- **Flask**: Web framework
- **Janome**: Japanese tokenization  
- **Whoosh**: Full-text search library (optional)
- **Bootstrap**: UI styling
- **uv**: Fast Python package manager

## Future Enhancements

- [ ] Add fuzzy search capabilities
- [ ] Implement document highlighting
- [ ] Add search history
- [ ] Support for document uploads
- [ ] Advanced search operators
- [ ] Search result pagination