# Preset: JSON Companies Processing
# Optimized for processing JSON company data with HTML content and DataFrame merging
# Usage: uv run python scripts/tokenize_csv.py --config-path conf/presets --config-name json_companies

input:
  csv_file: null
  json_folder: "data/test_json_companies"
  dataframe_file: "data/test_company_info.csv"
  
processing:
  batch_size: 500
  max_content_length: 10000
  extra_columns:
    - cust_status
  use_multiprocessing: true
  num_processes: null               # Auto-detect CPU cores
  use_hybrid_pipeline: true        # Enable hybrid async I/O + multiprocessing pipeline
  max_concurrent_io: 20             # Maximum concurrent I/O operations
  
output:
  output_dir: null                  # Auto-generate: data/test_json_companies/tokenized
  clear_output: false
  
tokenizer:
  included_pos: 
    - "名詞"
    - "動詞"
    - "形容詞"
    - "副詞"
  min_word_length: 2
  stop_words_filtered: true