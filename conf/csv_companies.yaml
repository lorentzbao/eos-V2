# Preset: CSV Companies Processing
# Optimized for processing structured CSV company data  
# Usage: uv run python scripts/tokenize_csv.py --config-path conf/presets --config-name csv_companies

input:
  csv_file: "data/sample_companies.csv"
  json_folder: null
  dataframe_file: null
  
processing:
  batch_size: 1000
  max_content_length: 10000
  extra_columns: null               # Not applicable for CSV input
  use_multiprocessing: true
  num_processes: null               # Auto-detect CPU cores
  
output:
  output_dir: null                  # Auto-generate: data/sample_companies/tokenized
  clear_output: true                # Clear existing output
  
tokenizer:
  included_pos: 
    - "名詞"
    - "動詞"
    - "形容詞"
    - "副詞"
  min_word_length: 2
  stop_words_filtered: true